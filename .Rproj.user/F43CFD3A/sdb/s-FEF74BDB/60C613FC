{
    "collab_server" : "",
    "contents" : "library(frontier)\nlibrary(data.table)\nlibrary(foreign)\nlibrary(quantreg)\nlibrary(npbr)\nlibrary(ggplot2)\nlibrary(countrycode)\nlibrary(RColorBrewer)\nlibrary(parallel)\nlibrary(Rglpk)\noptions(stringsAsFactors = FALSE)\nsource(\"~/Dropbox/Archive/unifying-study-asymmetric/functions.R\")\ncolors <- brewer.pal(7, \"Set1\")\n\ndat <- read.csv(\"~/Dropbox/Archive/unifying-study-asymmetric/Data_IO_fs-QCA.csv\")\ndat <- read.csv(\"~/Dropbox/Ongoing_Projects/unifying-study-asymmetric/Data_IO_fs-QCA.csv\")\n\ncountryname <- dat$X\ny <- dat$Supranationalist.government\nx <- dat$Strong.regional.governance * dat$High.policy.conformity\nka_qr <- rq(y ~ x, tau = 0.05)\nka_sfa <- sfa(y ~ x | x, ineffDecrease = FALSE)\ny <- 1 - y\nx <- 1 - x\nanalysis_dat <- data.frame(x, y, countryname)\nodeg <- opt_degree(xtab = analysis_dat$x, ytab = analysis_dat$y, x = analysis_dat$x, \n  prange=1:20)\npolfront <- poly_estimate(analysis_dat$x, analysis_dat$y, \n  x = analysis_dat$x, deg = odeg)\nbw <- kern_smooth_bw(x, y, method=\"u\", technique=\"noh\", bw_method=\"bic\")\nkernsmooth <- kernel_smoothing(x, y, x, h = bw)\n\nbs.routine(analysis_dat)\n\n## Do the bootstrapping 1000 times\nbs.est <- replicate(1000, bs.routine(dta = analysis_dat))\nbs.est <- replicate(1000, bs.routine.beta(dta = analysis_dat))\n\n\n\n#xs <- with(dat, Strong.regional.governance*High.policy.conformity)\npar(mar=c(4,3,3,0), pty = \"s\")\nplot(dat$Strong.regional.governance * dat$High.policy.conformity, \n     dat$Supranationalist.government, \n     main = \"Kernel Boundary Estimate for Koenig-Archibugi (2004)\", \n     xlim = c(0,1),\n     xlab = \"\",\n     ylab = \"\",\n     ylim = c(0,1), type = \"p\", pch = 19, col=\"gray\",\n     xaxp = c(0, 1, 1), yaxp = c(0, 1, 1), cex.lab = 0.8, cex.axis = 0.8,\n     cex = 1.5)\nmtext(\"Support for Supranational CFSP\", side=2, line=1)\nmtext(\"Combination of Regional Governance and Policy Conformity\", \n      side=1, line=1)\npoints(x = sort(1 - analysis_dat$x), y = sort(1 - kernsmooth), type = \"l\", \n       lwd = 2, col = colors[1], lty = \"twodash\")\nlegend.txt <- c(\"Kernel\", \"Boot (0.5)\")\nlegend('bottomright', legend.txt, lwd=2, \n  col=c(colors[1], colors[2]), lty = c(\"twodash\", \"dashed\"),bty='n', cex=.75)\n\nfor(i in 1:100)\n{\n   points(x = sort(1 - analysis_dat$x), y = sort(ymatrix[, i]), type = \"l\",\n     col = alpha(\"gray\", 0.45) , lwd = 2)\n}\n\nsampledatas <- lapply(1:1000, bs.sample, dta = analysis_dat)\nxs <- list()\nys <- list()\nfor(i in 1:1000)\n{\n  xs[[i]] <- sampledatas[[i]][,1]\n  ys[[i]] <- sampledatas[[i]][,2]\n}\n\nxs <- lapply(xs, sort)\nys <- lapply(ys, sort)\n\npolfronts <- list()\nfor(i in 1:1000)\n{\n  bw <- kern_smooth_bw(xs[[i]], ys[[i]], method=\"u\", technique=\"noh\", bw_method=\"bic\")\n  kernsmooth <- kernel_smoothing(xs[[i]], ys[[i]], xs[[i]], h = bw)\n  polfronts[[i]] <- c(1 - kernsmooth)\n}\n\nfor(i in 4:4)\n{\n  points(x = sort(1 - xs[[i]]), y = sort(polfronts[[i]]), type = \"l\",\n    #col = alpha(\"gray\", 0.95) , lwd = 2)\n    col = \"black\" , lwd = 2)\n}\n\n\npar(mar=c(4,3,3,0), pty = \"s\")\nplot(1 - sampledatas[[4]][,1], 1 - sampledatas[[4]][,2], \n     main = \"Kernel Boundary Estimate for Koenig-Archibugi (2004)\", \n     xlim = c(0,1),\n     xlab = \"\",\n     ylab = \"\",\n     ylim = c(0,1), type = \"p\")\n\n\n## ####################\n# DEVELOPMENT DOWN HERE\n## ####################\n# take the data in sufficient format and reverse it\nxvals <- sort(sampledatas[[2]][,1])\nyvals <- sort(sampledatas[[2]][,2])\nplot(xvals, yvals)\n# run the analysis on the reversed data\nbw <- kern_smooth_bw(xvals, yvals, method=\"u\", technique=\"noh\", bw_method=\"bic\")\ntest <- kernel_smoothing(xvals, yvals, xvals, h = bw)\n# plot by refersing back to original\nplot(1 - xvals, 1 - yvals)\npoints(x = sort(1 - xvals), y = sort(1 - test), type = \"l\")\n\n# NOW TRY A BUNCH\nbws <- c() \nkernsmooths <- matrix(NA, nrow = 13, ncol = 1000)\nxvals <- matrix(NA, nrow = 13, ncol = 1000)\nyvals <- matrix(NA, nrow = 13, ncol = 1000)\nfor(i in 1:1000)\n{  \nxvals[, i] <- sort(sampledatas[[i]][,1])\nyvals[, i] <- sort(sampledatas[[i]][,2])\nbws[i] <- kern_smooth_bw(xvals[, i], yvals[, i], method=\"u\", technique=\"noh\", \n  bw_method=\"bic\")\nkernsmooths[, i] <- kernel_smoothing(xvals[, i], yvals[, i], analysis_dat$x, h = bws[i])\n}\n\nfor(i in 1:5)\n{\n  plot(1 - xvals[, i], 1 - yvals[, i],\n       main = \"Kernel Boundary Estimate for Koenig-Archibugi (2004)\",\n       xlim = c(0,1),\n       xlab = \"\",\n       ylab = \"\", type = \"p\", ylim = c(0, 1))\n  points(x = sort(1 - xvals[, i]), y = sort(1 - kernsmooths[,i]), type = \"p\",\n         #col = alpha(\"gray\", 0.25) , lwd = 2)\n  col = \"red\" , lwd = 2)\n}\n\nplot(dat$Strong.regional.governance * dat$High.policy.conformity, \n     dat$Supranationalist.government, \n     main = \"Kernel Boundary Estimate for Koenig-Archibugi (2004)\", \n     xlim = c(0,1),\n     xlab = \"\",\n     ylab = \"\",\n     ylim = c(0,1), type = \"p\", pch = 19, col=\"gray\",\n     xaxp = c(0, 1, 1), yaxp = c(0, 1, 1), cex.lab = 0.8, cex.axis = 0.8,\n     cex = 1.5)\nfor(i in 1:100)\n{\n  points(x = sort(1 - xvals[, i]), y = sort(1 - kernsmooths[,i]), type = \"l\",\n         col = alpha(\"gray\", 0.25) , lwd = 2)\n}\n\nkernsmooths_plot <- apply(kernsmooths, 2, sort)\nkernsmooths_bounds <- apply(kernsmooths_plot, 1, quantile, probs = c(0.025, 0.975))\n# xvals_test <- apply(xvals, 2, sort)\n# xvals_test <- apply(xvals_test, 1, quantile, probs = c(0.025, 0.975))\npoints(x = sort(1 - analysis_dat$x), y = sort(1 - kernsmooths_bounds[1,]), type = \"l\",\n       col = \"black\", lwd = 2)\npoints(x = sort(1 - analysis_dat$x), y = sort(1 - kernsmooths_bouds[2,]), type = \"l\",\n       col = \"black\", lwd = 2)\nymeans <- apply(kernsmooths_plot, 1, quantile, probs = 0.5)\ninterval_lines_y <- apply(kernsmooths_plot, 1, quantile, probs = c(0.025, 0.975))\npoints(x = sort(1 - analysis_dat$x), y = sort(1 - interval_lines_y[1,]), type = \"l\",\n       col = \"black\", lwd = 2)\n\n\n\n\nxs <- with(dat, Strong.regional.governance*High.policy.conformity)\ndat$abbrv <- countrycode(as.character(dat$X), \"country.name\", \"iso3c\")\npar(mar=c(4,3,3,0), pty = \"s\")\nset.seed(5)\nplot(dat$Strong.regional.governance * dat$High.policy.conformity, \n     dat$Supranationalist.government, \n     main = \"Comparison of Methods on Koenig-Archibugi (2004)\", \n     xlim = c(0,1),\n     xlab = \"\",\n     ylab = \"\",\n     ylim = c(0,1), type = \"p\", pch = 19, col=\"#00000055\",\n     xaxp = c(0, 1, 1), yaxp = c(0, 1, 1), cex.lab = 0.8, cex.axis = 0.8,\n     cex = 1.5)\nwith(dat, text(jitter(Supranationalist.government, factor = 1) ~ xs, \n  labels = dat$abbrv, pos = 3, cex = 0.75))\nmtext(\"Support for Supranational CFSP\", side=2, line=1)\nmtext(\"Combination of Regional Governance and Policy Conformity\", \n      side=1, line=1)\nlegend.txt <- c(\"Kernel\", \"Boot (0.5)\")\nlegend('bottomright', legend.txt, lwd=2, \n  col=c(colors[1], colors[2]), lty = c(\"twodash\", \"dashed\"),bty='n', cex=.75)\npoints(x = sort(1 - analysis_dat$x), y = sort(1 - kernsmooth), type = \"l\", \n       lwd = 2, col = colors[1], lty = \"twodash\")\n# polygon(x = c(sort(1 - analysis_dat$x), rev(sort(1 - analysis_dat$x))), \n#         c(sort(kernsmooths_bounds[1, ]), rev(sort(kernsmooths_bounds[2, ]))), \n#         col = alpha(\"grey30\", 0.25), border = NA)\n# points(x = sort(1 - analysis_dat$x), y = ymeans, type = \"l\", \n#        col = colors[2] , lwd = 2, lty = \"dashed\")\n\n\n\n\n\n# points(x = sort(interval_lines_x[1,]), y = sort(interval_lines_y[1,]), type = \"l\",\n#   col = \"gray\", lwd = 2)\n# points(x = sort(interval_lines_x[2,]), y = sort(interval_lines_y[2,]), type = \"l\",\n#        col = \"gray\", lwd = 2)\n# points(x = xmeans, y = ymeans, type = \"l\", \n#        col = colors[2] , lwd = 2, lty = \"dashed\")\n# points(x = sort(1 - x), y = sort(1 - polfront), type = \"l\", \n#        col = \"blue\" , lwd = 2)\n\nymatrix <- apply(bs.est, 2, sort)\n\n\n# xmatrix <- do.call(rbind, xs)\n# xmatrix <- apply(xmatrix, 2, sort)\n# ymatrix <- do.call(rbind, ys)\n# ymatrix <- apply(ymatrix, 2, sort)\n\n#xmeans <- sort(apply(xmatrix, 1, quantile, probs = .5))\nymeans <- sort(apply(ymatrix, 1, quantile, probs = .5))\n\n\n#interval_lines_x <- apply(xmatrix, 2, quantile, probs = c(0.025, 0.975))\ninterval_lines_y <- apply(ymatrix, 1, quantile, probs = c(0.05, 0.95))\n\n# polygon(x = c(interval_lines_x[1, ], rev(interval_lines_x[2, ])), \n#         c(interval_lines_y[1, ], rev(interval_lines_y[2, ])), \n#         col = alpha(\"grey30\", 0.25), border = NA)\npolygon(x = c(sort(1 - analysis_dat$x), rev(sort(1 - analysis_dat$x))), \n        c(sort(interval_lines_y[1, ]), rev(sort(interval_lines_y[2, ]))), \n        col = alpha(\"grey30\", 0.25), border = NA)\npoints(x = sort(1 - analysis_dat$x), y = ymeans, type = \"l\", \n  col = colors[2] , lwd = 2, lty = \"dashed\")\n\n\n# AOC lower\nxmax <- max(1 - analysis_dat$x)\nxmin <- min(1 - analysis_dat$x)\nymax <- max(interval_lines_y[1, ])\nymin <- 0\ndivide_by_this <- (xmax-xmin)*(ymax-ymin)\nAUC_kern <- sum(diff(sort(1 - analysis_dat$x)) * rollmean(sort(interval_lines_y[1,]), 2)) \nAUC_percent <- AUC_kern/divide_by_this\nkern_result_lower <- 1 - AUC_percent\n\n# AOC Upper\nxmax <- max(1 - analysis_dat$x)\nxmin <- min(1 - analysis_dat$x)\nymax <- max(interval_lines_y[2, ])\nymin <- min(interval_lines_y[2,])\ndivide_by_this <- (xmax-xmin)*(ymax-ymin)\nAUC_kern <- sum(diff(sort(1 - analysis_dat$x)) * rollmean(sort(interval_lines_y[2,]), 2)) \nAUC_percent <- AUC_kern/divide_by_this\nkern_result_upper <- 1 - AUC_percent\n\n# AOC means\nxmax <- max(1 - analysis_dat$x)\nxmin <- min(1 - analysis_dat$x)\nymax <- max(ymeans)\nymin <- min(ymeans)\ndivide_by_this <- (xmax-xmin)*(ymax-ymin)\nAUC_kern <- sum(diff(sort(1 - analysis_dat$x)) * rollmean(sort(ymeans), 2)) \nAUC_lower <- sum(diff(sort(1 - analysis_dat$x)) * ymin)\nAUC_difference <- AUC_kern - AUC_lower\nAUC_percent <- AUC_difference/divide_by_this\nkern_result_means <- 1 - AUC_percent\n\n\n## health - wealth\n\n#Drew\ndat_gdp <- read.csv(\"~/Dropbox/Archive/unifying-study-asymmetric/health_wealth/gdp_ppp.csv\", stringsAsFactors = FALSE)\ndat_life <- read.csv(\"~/Dropbox/Archive/unifying-study-asymmetric/health_wealth/life_expect.csv\", stringsAsFactors = FALSE)\n\n# Austin\ndat_gdp <- read.csv(\"~/Dropbox/Ongoing_Projects/unifying-study-asymmetric/health_wealth/gdp_ppp.csv\", stringsAsFactors = FALSE)\ndat_life <- read.csv(\"~/Dropbox/Ongoing_Projects/unifying-study-asymmetric/health_wealth/life_expect.csv\", stringsAsFactors = FALSE)\n\n# log GDP\ndat_gdp[, 2:217] <- log(dat_gdp[, 2:217]) \n\ncolumnsgdp <- c(\"state\", paste(\"gdp\",seq(from = 1800, to = 2015), sep = \"_\"))\ncolumnslife <- c(\"state\", paste(\"life\",seq(from = 1800, to = 2015), sep = \"_\"))\ncolnames(dat_gdp) <- columnsgdp\ncolnames(dat_life) <- columnslife\ndat_life <- dat_life[,-1]\ndat <- data.frame(cbind(dat_gdp, dat_life))\npar(mar=c(4,3,3,0), pty = \"s\")\n\ndat <- dat[complete.cases(dat),]\n\nmydat <- data.frame(dat$gdp_1800, dat$life_1800)\n\nrm(dat, dat_life, dat_gdp, columnslife, columnsgdp)\n\nsetnames(mydat, c(\"gdp\", \"life\"))\nodeg1 <- opt_degree(mydat$gdp, mydat$life, mydat$gpd, prange=0:20)\npolfront_hw <- poly_estimate(mydat$gdp, mydat$life, mydat$gdp, deg = odeg1)\nhw_qr <- rq(life ~ gdp, tau = 0.95, data = mydat)\nhw_sfa <- sfa(mydat$life ~ mydat$gdp | mydat$gdp, ineffDecrease = TRUE)\nbw <- kern_smooth_bw(mydat$gdp, mydat$life, method=\"u\", \n  technique=\"noh\", bw_method=\"bic\")\nkernsmooth <- kernel_smoothing(mydat$gdp, mydat$life, mydat$gdp, h = bw)\nhw_ols <- lm(life ~ gdp, data = mydat)\n\n\n# Don't need to boostrap again, just load below\n# load bootstraps\nload(\"~/Dropbox/Archive/unifying-study-asymmetric/boot_degree.rdata\")\nnboots <- 1000\n \n# \nlapply(bootstrapped_data, setDT)\n# \n# degrees <- lapply(bootstrapped_data, bootstrap_degrees)\n#save(degrees, \n#  file = \"~/Dropbox/Archive/unifying-study-asymmetric/boot_degree.rdata\")\nbootstrapped_data <- lapply(1:nboots, bs.sample, dta = mydat)\nhw_bs_est <- lapply(1:nboots, bootstrap_estimates)\n\nwealth <- lapply(bootstrapped_data, comb_dat)\n\nhw_plot_data <- lapply(1:nboots, put_wealth_health_together)\n\n# for(i in 1:nboots)\n# {\n#   points(x = sort(hw_plot_data[[i]][, 1]), y = sort(hw_plot_data[[i]][, 2]), \n#     type = \"l\", col = alpha(\"black\", 0.25), lwd = 1)\n# }\n\n#wealth <- lapply(wealth, sort)\n\nhw_bs_est <- lapply(hw_bs_est, sort)\n\n\n#xmatrix <- do.call(rbind, wealth)\n\nymatrix <- t(do.call(cbind, hw_bs_est))\n\n#xmeans <- sort(apply(xmatrix, 2, quantile, probs = .5))\n\nymeans <- sort(apply(ymatrix, 2, quantile, probs = .5))\n\n#final_plot_data[[1]][,1]\n# xs <- matrix(NA, ncol = 184, nrow = 100)\n# ys <- matrix(NA, ncol = 184, nrow = 100)\n# for(i in 1:100){\n#   xs[i,] <- final_plot_data[[i]][,1]\n# }\n# for(i in 1:100){\n#   ys[i,] <- final_plot_data[[i]][,2]\n# }\n# xmatrix <- apply(xs, 1, sort)\n# ymatrix <- apply(ys, 1, sort)\n#interval_lines_x <- apply(xmatrix, 2, quantile, probs = c(0.025, 0.975))\ninterval_lines_y <- apply(ymatrix, 2, quantile, probs = c(0.05, 0.95))\ninterval_lines_y <- apply(interval_lines_y, 1, sort)\n\n\nlegend.txt <- c(\"Poly\", \"QR (.95)\", \"SFA\", \"Kernel\", \"OLS\", \"Boot (.5)\")\nplot(mydat$gdp, mydat$life, xlab = \"Log GDP/Cap, PPP\",\n     ylab = \"Life Expectancy\", \n     main = \"Health and Wealth in 1800\", \n     pch = 19, col=\"#00000055\")\nlegend('bottomright', legend.txt, \n       lty=c(\"longdash\", \"dotted\", \"dotdash\", \"twodash\", \"solid\", \"dashed\"), \n       col=c(colors[3], colors[4],colors[5], colors[1], colors[7], colors[2]), \n       bty='n', cex=.75, lwd = 2)\npoints(x = sort(mydat$gdp), y = sort(polfront_hw), type = \"l\", \n       lwd = 2, col = colors[3], lty = \"longdash\")\nabline(a = hw_qr$coefficients[1] , b = hw_qr$coefficients[2], col = colors[4],\n       lty = \"dotted\", lwd = 2)\nabline(a = hw_sfa$mleParam[1], b = hw_sfa$mleParam[2], col = colors[5],\n       lty = \"dotdash\", lwd = 2)\nabline(a = hw_ols$coefficients[1], b = hw_ols$coefficients[2], col = colors[7],\n       lty = 1, lwd = 2)\npoints(x = sort(mydat$gdp), y = sort(kernsmooth), type = \"l\", lwd = 2, \n       col = colors[1], lty = \"twodash\")\n\n#points(x = sort(xmeans), y = sort(ymeans), type = \"l\", col = \"red\" , lwd = 2)\n\n\n#interval_lines_x <- apply(interval_lines_x, 1, sort)\npoints(x = sort(mydat$gdp), y = interval_lines_y[,1], type = \"l\", lwd = 2,\n       col = \"red\")\npoints(x = sort(mydat$gdp), y = interval_lines_y[,2], type = \"l\", lwd = 2,\n       col = \"red\")\n\n# polygon(x = c(interval_lines_x[, 1], rev(interval_lines_x[, 2])), \n#         c(interval_lines_y[, 1], rev(interval_lines_y[, 2])), \n#         col = alpha(\"grey30\", 0.25), border = NA)\npolygon(x = c(sort(mydat$gdp), rev(sort(mydat$gdp))), \n        c(interval_lines_y[, 1], rev(interval_lines_y[, 2])), \n        col = alpha(\"grey30\", 0.25), border = NA)\npoints(x = sort(mydat$gdp), y = ymeans, type = \"l\", col = colors[2] , lwd = 2, \n  lty = \"dashed\")\n\n\n",
    "created" : 1483796811409.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2181816170",
    "id" : "60C613FC",
    "lastKnownWriteTime" : 1479059753,
    "last_content_update" : 1479059753,
    "path" : "~/Dropbox/Archive/unifying-study-asymmetric/bootstrap_nlm.R",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 5,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}